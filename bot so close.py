from telegram.ext import Application, ContextTypes, JobQueue
import feedparser
from deep_translator import GoogleTranslator
from transformers import pipeline
import hashlib
import logging
import re
import requests
import asyncio
import psutil
import time
from datetime import datetime, timedelta
from urllib.parse import urlparse

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
try:
    import psutil
except ImportError:
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ psutil: pip install psutil")
    exit(1)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    filename='news_bot.log',
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

class NewsBot:
    def __init__(self, token: str, channel_id: str):
        self.token = token
        self.channel_id = channel_id
        self.feeds = [
            'https://lenta.ru/rss/news',
            'https://www.vedomosti.ru/rss/news'
        ]
        self.news_processor = EnhancedNewsProcessor()
        self.application = Application.builder().token(token).build()
        
        self.health_stats = {
            'sent': 0,
            'errors': 0,
            'last_check': datetime.now()
        }

    async def fetch_news(self, context: ContextTypes.DEFAULT_TYPE):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–ª—É—á–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        try:
            for feed_url in self.feeds:
                feed = feedparser.parse(feed_url)
                
                if feed.bozo:
                    logger.error(f"–û—à–∏–±–∫–∞ RSS: {feed.bozo_exception}")
                    continue
                
                for entry in feed.entries[:5]:
                    message, image = self.news_processor.process_entry(entry)
                    if message:
                        await self._send_message_with_retry(message, image)
                        self.health_stats['sent'] += 1
                        await asyncio.sleep(1)
            
            self.health_stats['last_check'] = datetime.now()
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞: {str(e)}", exc_info=True)
            self.health_stats['errors'] += 1

    async def _send_message_with_retry(self, text: str, image_url: str = None):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å 3 –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        for attempt in range(3):
            try:
                if image_url:
                    await self.application.bot.send_photo(
                        chat_id=self.channel_id,
                        photo=image_url,
                        caption=text,
                        parse_mode='MarkdownV2'
                    )
                else:
                    await self.application.bot.send_message(
                        chat_id=self.channel_id,
                        text=text,
                        parse_mode='MarkdownV2',
                        disable_web_page_preview=True
                    )
                return
            except Exception as e:
                logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt+1} –æ—à–∏–±–∫–∞: {str(e)}")
                await asyncio.sleep(2 ** attempt)
        
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ")
        self.health_stats['errors'] += 1

    def start(self):
        """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–∞
            response = requests.get(f"https://api.telegram.org/bot{self.token}/getMe")
            if response.status_code != 200:
                logger.critical("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–æ–∫–µ–Ω –±–æ—Ç–∞")
                exit(1)

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
            job_queue = self.application.job_queue
            job_queue.run_repeating(
                self.fetch_news, 
                interval=1800,  # 30 –º–∏–Ω—É—Ç
                first=10
            )

            # –ó–∞–ø—É—Å–∫
            self.application.run_polling()
            logger.info("–ë–æ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω")

        except Exception as e:
            logger.critical(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {str(e)}")
            exit(1)

class EnhancedNewsProcessor:
    def __init__(self):
        self.translator = GoogleTranslator(source='auto', target='ru')
        self.summarizer = pipeline("summarization", model="IlyaGusev/rut5_base_sum_gazeta")
        self.cache = set()
        self.last_cache_clean = datetime.now()

    def _clean_cache(self):
        """–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –∫–∞–∂–¥—ã–µ 2 —á–∞—Å–∞"""
        if (datetime.now() - self.last_cache_clean).total_seconds() > 7200:
            self.cache.clear()
            self.last_cache_clean = datetime.now()

    def process_entry(self, entry) -> tuple:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ RSS-–∑–∞–ø–∏—Å–∏"""
        try:
            self._clean_cache()
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ —Ö–µ—à–∞
            entry_hash = hashlib.sha256(entry.link.encode()).hexdigest()
            if entry_hash in self.cache:
                return None, None

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
            pub_date = datetime(*entry.published_parsed[:6]) if hasattr(entry, 'published_parsed') else None
            if pub_date and (datetime.now() - pub_date).days > 1:
                return None, None

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            title = self._process_text(entry.title)
            if not title:
                return None, None

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            content = self._process_text(getattr(entry, 'description', ''))
            summary = self.summarizer(
                content,
                max_length=150,
                min_length=50,
                do_sample=False
            )[0]['summary_text']

            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            message = (
                f"üìå *{title}*\n\n"
                f"{summary}\n\n"
                f"[–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é]({entry.link})"
            )

            # –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_url = self._find_image(entry)

            self.cache.add(entry_hash)
            return message, image_url

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
            return None, None

    def _process_text(self, text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ –∏ –ø–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞"""
        clean_text = re.sub(r'<[^>]+>|[\t\r\n]+', ' ', text).strip()
        if not clean_text:
            return ""
            
        try:
            return self.translator.translate(clean_text[:2000])
        except Exception:
            return clean_text[:1000]

    def _find_image(self, entry) -> str:
        """–ü–æ–∏—Å–∫ –≤–∞–ª–∏–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        for enclosure in getattr(entry, 'enclosures', []):
            if enclosure.type.startswith('image/'):
                return enclosure.href
        return ""

if __name__ == '__main__':
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    BOT_TOKEN = '7991018460:AAH7l8b1HbX09YlJgCTiWQRyWlzeHeIYBgM'
    CHANNEL_ID = '@proriv14'

    try:
        bot = NewsBot(BOT_TOKEN, CHANNEL_ID)
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞...")
        bot.start()
    except KeyboardInterrupt:
        logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–æ—Ç–∞")
    except Exception as e:
        logger.critical(f"–§–ê–¢–ê–õ–¨–ù–ê–Ø –û–®–ò–ë–ö–ê: {str(e)}")
        exit(1)
